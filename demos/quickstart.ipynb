{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBoxMaskPose Quickstart\n",
    "\n",
    "This notebook demonstrates the public API for both PMPose and BBoxMaskPose.\n",
    "\n",
    "## Installation Reminder\n",
    "\n",
    "Before running this notebook, ensure you have installed BBoxMaskPose:\n",
    "\n",
    "```bash\n",
    "# Install dependencies\n",
    "pip install -U openmim\n",
    "mim install mmengine \"mmcv==2.1.0\" \"mmdet==3.3.0\" \"mmpretrain==1.2.0\"\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Install in editable mode\n",
    "pip install -e .\n",
    "\n",
    "# Download SAM2 weights\n",
    "bash models/SAM/download_ckpts.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: PMPose - Pose Estimation with Bounding Boxes\n",
    "\n",
    "PMPose (currently MaskPose) performs pose estimation given an image and bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import PMPose public API\n",
    "from pmpose import PMPose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize PMPose Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PMPose with pretrained weights\n",
    "pose_model = PMPose(\n",
    "    device=\"cuda\",           # Use 'cpu' if no GPU available\n",
    "    variant=\"default\",       # Default MaskPose-b model\n",
    "    from_pretrained=True,    # Download pretrained weights\n",
    ")\n",
    "\n",
    "print(\"✓ PMPose model initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image and Define Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example image\n",
    "image_path = \"demo/data/004806.jpg\"\n",
    "img = cv2.imread(image_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display image\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"Input Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Define bounding boxes for people in the image [x1, y1, x2, y2]\n",
    "bboxes = np.array([\n",
    "    [180, 100, 380, 500],   # Person 1\n",
    "    [350, 150, 550, 500],   # Person 2\n",
    "    [500, 120, 700, 480],   # Person 3\n",
    "], dtype=np.float32)\n",
    "\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Number of bboxes: {len(bboxes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pose estimation\n",
    "keypoints, presence, visibility, heatmaps = pose_model.predict(\n",
    "    image=img,\n",
    "    bboxes=bboxes,\n",
    "    masks=None,              # Optional instance masks\n",
    "    return_probmaps=False,   # Set True to get heatmaps\n",
    ")\n",
    "\n",
    "print(f\"Keypoints shape: {keypoints.shape}\")       # (N, K, 3) - [x, y, score]\n",
    "print(f\"Presence shape: {presence.shape}\")         # (N, K) - presence probability\n",
    "print(f\"Visibility shape: {visibility.shape}\")     # (N, K) - visibility flag\n",
    "\n",
    "# Print average confidence per person\n",
    "for i in range(len(keypoints)):\n",
    "    avg_conf = keypoints[i, :, 2].mean()\n",
    "    print(f\"Person {i+1}: average confidence = {avg_conf:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pose estimation results\n",
    "vis_img = pose_model.visualize(\n",
    "    image=img,\n",
    "    keypoints=keypoints,\n",
    "    bboxes=bboxes,\n",
    ")\n",
    "\n",
    "# Display\n",
    "vis_img_rgb = cv2.cvtColor(vis_img, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(vis_img_rgb)\n",
    "plt.title(\"PMPose Results\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: BBoxMaskPose - Full Detection + Pose + Segmentation Pipeline\n",
    "\n",
    "BBoxMaskPose runs the complete pipeline: detection → pose estimation → SAM refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BBoxMaskPose public API\n",
    "from bboxmaskpose import BBoxMaskPose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: BMP with Internal Pose Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BBoxMaskPose (creates internal PMPose)\n",
    "bmp_model = BBoxMaskPose(\n",
    "    config=\"BMP_D3\",         # BMP configuration\n",
    "    device=\"cuda\",           # Use 'cpu' if no GPU\n",
    "    pose_model=None,         # Let BMP create internal model\n",
    ")\n",
    "\n",
    "print(\"✓ BBoxMaskPose initialized with internal pose model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full BMP pipeline\n",
    "result = bmp_model.predict(\n",
    "    image=image_path,\n",
    "    bboxes=None,             # Let detector find bboxes\n",
    "    return_intermediates=False,\n",
    ")\n",
    "\n",
    "print(f\"Detected {len(result['bboxes'])} people\")\n",
    "print(f\"Keypoints shape: {result['keypoints'].shape}\")\n",
    "print(f\"Masks shape: {result['masks'].shape}\")\n",
    "print(f\"Presence shape: {result['presence'].shape}\")\n",
    "print(f\"Visibility shape: {result['visibility'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize BMP Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize complete results\n",
    "vis_img = bmp_model.visualize(\n",
    "    image=image_path,\n",
    "    result=result,\n",
    ")\n",
    "\n",
    "# Display\n",
    "vis_img_rgb = cv2.cvtColor(vis_img, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(vis_img_rgb)\n",
    "plt.title(\"BBoxMaskPose Results\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: BMP with External PMPose Model\n",
    "\n",
    "You can also create a PMPose model separately and inject it into BMP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PMPose model first\n",
    "my_pose_model = PMPose(\n",
    "    device=\"cuda\",\n",
    "    variant=\"default\",\n",
    "    from_pretrained=True,\n",
    ")\n",
    "\n",
    "# Inject into BBoxMaskPose\n",
    "bmp_model_with_external_pose = BBoxMaskPose(\n",
    "    config=\"BMP_D3\",\n",
    "    device=\"cuda\",\n",
    "    pose_model=my_pose_model,   # Use our PMPose instance\n",
    ")\n",
    "\n",
    "print(\"✓ BBoxMaskPose initialized with external pose model\")\n",
    "\n",
    "# Run pipeline (same as before)\n",
    "result2 = bmp_model_with_external_pose.predict(\n",
    "    image=image_path,\n",
    "    bboxes=None,\n",
    ")\n",
    "\n",
    "print(f\"Detected {len(result2['bboxes'])} people\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **PMPose API**: Pose estimation with bounding boxes\n",
    "   - `PMPose()` initialization\n",
    "   - `predict()` for inference\n",
    "   - `visualize()` for visualization\n",
    "\n",
    "2. **BBoxMaskPose API**: Full detection + pose + segmentation pipeline\n",
    "   - Internal pose model creation\n",
    "   - External pose model injection\n",
    "   - `predict()` for full pipeline\n",
    "   - `visualize()` for results\n",
    "\n",
    "Both APIs provide stable, easy-to-use interfaces while maintaining backward compatibility with the underlying MaskPose model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
